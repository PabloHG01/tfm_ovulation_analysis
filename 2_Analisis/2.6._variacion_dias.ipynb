{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fc5710f",
   "metadata": {},
   "source": [
    "# Pruebas con tests estadísticos para comprobar el salto térmico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbf43095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_rel, shapiro, wilcoxon, t\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaae338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_ref = pd.Timestamp('2025-01-01 00:00:00').floor('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fd62c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir rangos de días para probar\n",
    "dias_antes = [-3, -2, -1, 0] \n",
    "dias_despues = [2, 3, 4, 5, 6] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dbedde",
   "metadata": {},
   "source": [
    "### Series alineadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3a915b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../procData/muestras_ovul_horas_norm1.pkl\", \"rb\") as f:\n",
    "    muestras_alin = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07eef51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top resultados ordenados por error estándar en la diferencia:\n",
      "    dia_antes  dia_despues  wilcoxon_p  shapiro_p   ttest_p  media_dif  \\\n",
      "11         -1            3    0.000006   0.001174       NaN   0.061000   \n",
      "6          -2            3    0.000008   0.000542       NaN   0.062136   \n",
      "12         -1            4    0.000009   0.029508       NaN   0.056828   \n",
      "1          -3            3    0.000010   0.007244       NaN   0.062798   \n",
      "2          -3            4    0.000041   0.201102  0.000227   0.058627   \n",
      "7          -2            4    0.000051   0.071249  0.000491   0.057964   \n",
      "3          -3            5    0.000065   0.104604  0.000229   0.063001   \n",
      "8          -2            5    0.000076   0.243531  0.000461   0.062338   \n",
      "5          -2            2    0.000099   0.005295       NaN   0.046112   \n",
      "10         -1            2    0.000112   0.467437  0.000303   0.044977   \n",
      "\n",
      "     std_err  int_conf_inf  int_conf_sup  \n",
      "11  0.014360      0.032255      0.089745  \n",
      "6   0.015036      0.032038      0.092234  \n",
      "12  0.012016      0.032775      0.080881  \n",
      "1   0.014762      0.033250      0.092347  \n",
      "2   0.014911      0.028780      0.088473  \n",
      "7   0.015694      0.026550      0.089379  \n",
      "3   0.016032      0.030909      0.095092  \n",
      "8   0.016786      0.028737      0.095940  \n",
      "5   0.013043      0.020004      0.072221  \n",
      "10  0.011701      0.021556      0.068398  \n"
     ]
    }
   ],
   "source": [
    "resultados_alin = []\n",
    "\n",
    "for dia_antes in dias_antes:\n",
    "    for dia_despues in dias_despues:\n",
    "        valores_antes = []\n",
    "        valores_despues = []\n",
    "\n",
    "        for key, data in muestras_alin.items():\n",
    "            df = data[\"serie\"].copy()\n",
    "            # Calcular días relativos (decimales)\n",
    "            df[\"dias_rel\"] = (df[\"resultTimestamp\"] - fecha_ref) / pd.Timedelta(days=1)\n",
    "            \n",
    "            # Agrupar por día entero redondeado para obtener medias diarias\n",
    "            df[\"dia_entero\"] = df[\"dias_rel\"].round().astype(int)\n",
    "            medias_diarias = df.groupby(\"dia_entero\")[\"result\"].mean()\n",
    "\n",
    "            # Extraer medias del día antes y día después\n",
    "            # Si no hay datos para ese día, se puede usar NaN o saltar ese sujeto\n",
    "            val_antes = medias_diarias.get(dia_antes, np.nan)\n",
    "            val_despues = medias_diarias.get(dia_despues, np.nan)\n",
    "\n",
    "            # Sólo añadimos si ambos valores existen\n",
    "            if not (np.isnan(val_antes) or np.isnan(val_despues)):\n",
    "                valores_antes.append(val_antes)\n",
    "                valores_despues.append(val_despues)\n",
    "\n",
    "        valores_antes = np.array(valores_antes)\n",
    "        valores_despues = np.array(valores_despues)\n",
    "        diferencias = valores_despues - valores_antes\n",
    "\n",
    "        # Wilcoxon test para ascenso (antes < despues)\n",
    "        stat_wil, p_wil = wilcoxon(valores_antes, valores_despues, alternative='less')\n",
    "\n",
    "        # Shapiro para normalidad de diferencias\n",
    "        stat_shap, p_shap = shapiro(diferencias)\n",
    "\n",
    "        # Decide qué test t hacer o no\n",
    "        if p_shap > 0.05:\n",
    "            # Normalidad aceptada -> test t pareado\n",
    "            stat_t, p_t = ttest_rel(valores_despues, valores_antes)\n",
    "        else:\n",
    "            stat_t, p_t = np.nan, np.nan  # no se hace test t\n",
    "\n",
    "        # Media e intervalo confianza diferencia\n",
    "        media_dif = np.mean(diferencias)\n",
    "        std_dif = np.std(diferencias, ddof=1)\n",
    "        n = len(diferencias)\n",
    "\n",
    "        alpha = 0.05\n",
    "        t_crit = t.ppf(1 - alpha/2, df=n-1)\n",
    "        error_estandar = std_dif / np.sqrt(n)\n",
    "        ic_inf = media_dif - t_crit * error_estandar\n",
    "        ic_sup = media_dif + t_crit * error_estandar\n",
    "\n",
    "        resultados_alin.append({\n",
    "            \"dia_antes\": dia_antes,\n",
    "            \"dia_despues\": dia_despues,\n",
    "            \"wilcoxon_p\": p_wil,\n",
    "            \"shapiro_p\": p_shap,\n",
    "            \"ttest_p\": p_t,\n",
    "            \"media_dif\": media_dif,\n",
    "            \"std_err\": error_estandar,\n",
    "            \"int_conf_inf\": ic_inf,\n",
    "            \"int_conf_sup\": ic_sup\n",
    "        })\n",
    "\n",
    "df_resultados_alin = pd.DataFrame(resultados_alin)\n",
    "\n",
    "print(\"Top resultados ordenados por error estándar en la diferencia:\")\n",
    "print(df_resultados_alin.sort_values(\"wilcoxon_p\").head(10)[\n",
    "    [\"dia_antes\", \"dia_despues\", \"wilcoxon_p\", \"shapiro_p\", \"ttest_p\", \"media_dif\", \"std_err\", \"int_conf_inf\", \"int_conf_sup\"]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d8c64b",
   "metadata": {},
   "source": [
    "### Series normalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c117c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../procData/muestras_ovul_horas_norm2.pkl\", \"rb\") as f:\n",
    "    muestras_norm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65333173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top resultados ordenados por error estándar en la diferencia:\n",
      "    dia_antes  dia_despues  wilcoxon_p  shapiro_p   ttest_p  media_dif  \\\n",
      "11         -1            3    0.000005   0.170149  0.000009   0.425357   \n",
      "12         -1            4    0.000008   0.034137       NaN   0.358314   \n",
      "6          -2            3    0.000008   0.024812       NaN   0.427624   \n",
      "1          -3            3    0.000015   0.153971  0.000028   0.422401   \n",
      "13         -1            5    0.000039   0.483251  0.000013   0.429586   \n",
      "3          -3            5    0.000041   0.409952  0.000088   0.426630   \n",
      "2          -3            4    0.000056   0.049897       NaN   0.355357   \n",
      "8          -2            5    0.000065   0.884619  0.000091   0.431853   \n",
      "10         -1            2    0.000073   0.440218  0.000113   0.325392   \n",
      "7          -2            4    0.000091   0.170498  0.000319   0.360581   \n",
      "\n",
      "     std_err  int_conf_inf  int_conf_sup  \n",
      "11  0.087434      0.250338      0.600376  \n",
      "12  0.077987      0.202206      0.514422  \n",
      "6   0.088791      0.249891      0.605358  \n",
      "1   0.092919      0.236403      0.608398  \n",
      "13  0.090324      0.248784      0.610389  \n",
      "3   0.101201      0.224053      0.629206  \n",
      "2   0.093213      0.168771      0.541943  \n",
      "8   0.102627      0.226422      0.637285  \n",
      "10  0.078537      0.168182      0.482601  \n",
      "7   0.094184      0.172052      0.549110  \n"
     ]
    }
   ],
   "source": [
    "resultados_norm = []\n",
    "\n",
    "for dia_antes in dias_antes:\n",
    "    for dia_despues in dias_despues:\n",
    "        valores_antes = []\n",
    "        valores_despues = []\n",
    "\n",
    "        for key, data in muestras_norm.items():\n",
    "            df = data[\"serie\"].copy()\n",
    "            # Calcular días relativos (decimales)\n",
    "            df[\"dias_rel\"] = (df[\"resultTimestamp\"] - fecha_ref) / pd.Timedelta(days=1)\n",
    "            \n",
    "            # Agrupar por día entero redondeado para obtener medias diarias\n",
    "            df[\"dia_entero\"] = df[\"dias_rel\"].round().astype(int)\n",
    "            medias_diarias = df.groupby(\"dia_entero\")[\"result\"].mean()\n",
    "\n",
    "            # Extraer medias del día antes y día después\n",
    "            # Si no hay datos para ese día, se puede usar NaN o saltar ese sujeto\n",
    "            val_antes = medias_diarias.get(dia_antes, np.nan)\n",
    "            val_despues = medias_diarias.get(dia_despues, np.nan)\n",
    "\n",
    "            # Sólo añadimos si ambos valores existen\n",
    "            if not (np.isnan(val_antes) or np.isnan(val_despues)):\n",
    "                valores_antes.append(val_antes)\n",
    "                valores_despues.append(val_despues)\n",
    "\n",
    "        valores_antes = np.array(valores_antes)\n",
    "        valores_despues = np.array(valores_despues)\n",
    "        diferencias = valores_despues - valores_antes\n",
    "\n",
    "        # Wilcoxon test para ascenso (antes < despues)\n",
    "        stat_wil, p_wil = wilcoxon(valores_antes, valores_despues, alternative='less')\n",
    "\n",
    "        # Shapiro para normalidad de diferencias\n",
    "        stat_shap, p_shap = shapiro(diferencias)\n",
    "\n",
    "        # Decide qué test t hacer o no\n",
    "        if p_shap > 0.05:\n",
    "            # Normalidad aceptada -> test t pareado\n",
    "            stat_t, p_t = ttest_rel(valores_despues, valores_antes)\n",
    "        else:\n",
    "            stat_t, p_t = np.nan, np.nan  # no se hace test t\n",
    "\n",
    "        # Media e intervalo confianza diferencia\n",
    "        media_dif = np.mean(diferencias)\n",
    "        std_dif = np.std(diferencias, ddof=1)\n",
    "        n = len(diferencias)\n",
    "\n",
    "        alpha = 0.05\n",
    "        t_crit = t.ppf(1 - alpha/2, df=n-1)\n",
    "        error_estandar = std_dif / np.sqrt(n)\n",
    "        ic_inf = media_dif - t_crit * error_estandar\n",
    "        ic_sup = media_dif + t_crit * error_estandar\n",
    "\n",
    "        resultados_norm.append({\n",
    "            \"dia_antes\": dia_antes,\n",
    "            \"dia_despues\": dia_despues,\n",
    "            \"wilcoxon_p\": p_wil,\n",
    "            \"shapiro_p\": p_shap,\n",
    "            \"ttest_p\": p_t,\n",
    "            \"media_dif\": media_dif,\n",
    "            \"std_err\": error_estandar,\n",
    "            \"int_conf_inf\": ic_inf,\n",
    "            \"int_conf_sup\": ic_sup\n",
    "        })\n",
    "\n",
    "df_resultados_norm = pd.DataFrame(resultados_norm)\n",
    "\n",
    "print(\"Top resultados ordenados por error estándar en la diferencia:\")\n",
    "print(df_resultados_norm.sort_values(\"wilcoxon_p\").head(10)[\n",
    "    [\"dia_antes\", \"dia_despues\", \"wilcoxon_p\", \"shapiro_p\", \"ttest_p\", \"media_dif\", \"std_err\", \"int_conf_inf\", \"int_conf_sup\"]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37627719",
   "metadata": {},
   "source": [
    "### Tendencia de las series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be305718",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../procData/muestras_ovul_tend.pkl\", \"rb\") as f:\n",
    "    muestras_tendencia = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c32dc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top resultados ordenados por error estándar en la diferencia:\n",
      "    dia_antes  dia_despues  wilcoxon_p  shapiro_p   ttest_p  media_dif  \\\n",
      "6          -2            3    0.000003   0.060195  0.000013   0.054793   \n",
      "11         -1            3    0.000004   0.007297       NaN   0.049024   \n",
      "10         -1            2    0.000007   0.369774  0.000015   0.045103   \n",
      "5          -2            2    0.000012   0.093179  0.000005   0.050872   \n",
      "12         -1            4    0.000016   0.198937  0.000044   0.045422   \n",
      "7          -2            4    0.000020   0.721362  0.000029   0.051190   \n",
      "8          -2            5    0.000024   0.430456  0.000059   0.045211   \n",
      "9          -2            6    0.000035   0.899090  0.000027   0.050512   \n",
      "1          -3            3    0.000063   0.006695       NaN   0.047049   \n",
      "14         -1            6    0.000119   0.828160  0.000259   0.044743   \n",
      "\n",
      "     std_err  int_conf_inf  int_conf_sup  \n",
      "6   0.011494      0.031785      0.077801  \n",
      "11  0.011164      0.026678      0.071371  \n",
      "10  0.009534      0.026018      0.064188  \n",
      "5   0.010072      0.030710      0.071034  \n",
      "12  0.010285      0.024835      0.066009  \n",
      "7   0.011270      0.028630      0.073750  \n",
      "8   0.010432      0.024330      0.066093  \n",
      "9   0.011078      0.028338      0.072686  \n",
      "1   0.013220      0.020587      0.073511  \n",
      "14  0.011497      0.021729      0.067758  \n"
     ]
    }
   ],
   "source": [
    "resultados = []\n",
    "\n",
    "for dia_antes in dias_antes:\n",
    "    for dia_despues in dias_despues:\n",
    "        valores_antes = []\n",
    "        valores_despues = []\n",
    "\n",
    "        for key, data in muestras_tendencia.items():\n",
    "            df = data[\"serie\"].copy()\n",
    "            # Calcular días relativos (decimales)\n",
    "            df[\"dias_rel\"] = (df[\"resultTimestamp\"] - fecha_ref) / pd.Timedelta(days=1)\n",
    "            \n",
    "            # Agrupar por día entero redondeado para obtener medias diarias\n",
    "            df[\"dia_entero\"] = df[\"dias_rel\"].round().astype(int)\n",
    "            medias_diarias = df.groupby(\"dia_entero\")[\"tendencia\"].mean()\n",
    "\n",
    "            # Extraer medias del día antes y día después\n",
    "            # Si no hay datos para ese día, se puede usar NaN o saltar ese sujeto\n",
    "            val_antes = medias_diarias.get(dia_antes, np.nan)\n",
    "            val_despues = medias_diarias.get(dia_despues, np.nan)\n",
    "\n",
    "            # Sólo añadimos si ambos valores existen\n",
    "            if not (np.isnan(val_antes) or np.isnan(val_despues)):\n",
    "                valores_antes.append(val_antes)\n",
    "                valores_despues.append(val_despues)\n",
    "\n",
    "        valores_antes = np.array(valores_antes)\n",
    "        valores_despues = np.array(valores_despues)\n",
    "        diferencias = valores_despues - valores_antes\n",
    "\n",
    "        # Wilcoxon test para ascenso (antes < despues)\n",
    "        stat_wil, p_wil = wilcoxon(valores_antes, valores_despues, alternative='less')\n",
    "\n",
    "        # Shapiro para normalidad de diferencias\n",
    "        stat_shap, p_shap = shapiro(diferencias)\n",
    "\n",
    "        # Decide qué test t hacer o no\n",
    "        if p_shap > 0.05:\n",
    "            # Normalidad aceptada -> test t pareado\n",
    "            stat_t, p_t = ttest_rel(valores_despues, valores_antes)\n",
    "        else:\n",
    "            stat_t, p_t = np.nan, np.nan  # no se hace test t\n",
    "\n",
    "        # Media e intervalo confianza diferencia\n",
    "        media_dif = np.mean(diferencias)\n",
    "        std_dif = np.std(diferencias, ddof=1)\n",
    "        n = len(diferencias)\n",
    "\n",
    "        alpha = 0.05\n",
    "        t_crit = t.ppf(1 - alpha/2, df=n-1)\n",
    "        error_estandar = std_dif / np.sqrt(n)\n",
    "        ic_inf = media_dif - t_crit * error_estandar\n",
    "        ic_sup = media_dif + t_crit * error_estandar\n",
    "\n",
    "        resultados.append({\n",
    "            \"dia_antes\": dia_antes,\n",
    "            \"dia_despues\": dia_despues,\n",
    "            \"wilcoxon_p\": p_wil,\n",
    "            \"shapiro_p\": p_shap,\n",
    "            \"ttest_p\": p_t,\n",
    "            \"media_dif\": media_dif,\n",
    "            \"std_err\": error_estandar,\n",
    "            \"int_conf_inf\": ic_inf,\n",
    "            \"int_conf_sup\": ic_sup\n",
    "        })\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "print(\"Top resultados ordenados por error estándar en la diferencia:\")\n",
    "print(df_resultados.sort_values(\"wilcoxon_p\").head(10)[\n",
    "    [\"dia_antes\", \"dia_despues\", \"wilcoxon_p\", \"shapiro_p\", \"ttest_p\", \"media_dif\", \"std_err\", \"int_conf_inf\", \"int_conf_sup\"]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbe9f06",
   "metadata": {},
   "source": [
    "### Valores óptimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4b36ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejores valores:\n",
    "dia_antes_opt = -1\n",
    "dia_despues_opt = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfbf7be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANGE_VISUALIZ_Y = [36.0, 37.0]\n",
    "RANGE_VISUALIZ_X = [-5, 8]\n",
    "\n",
    "def print_series(dia_antes_opt, dia_despues_opt):\n",
    "    fecha_ref = pd.Timestamp('2025-01-01 00:00:00').floor('h')\n",
    "\n",
    "    for id in muestras_tendencia.keys(): \n",
    "        serie = muestras_tendencia[id][\"serie\"]\n",
    "\n",
    "        # Convertimos las fechas a días relativos a la ovulación\n",
    "        x = (serie[\"resultTimestamp\"] - fecha_ref) / pd.Timedelta(days=1)\n",
    "        y = serie[\"tendencia\"]\n",
    "\n",
    "        plt.figure(figsize=(8, 4))\n",
    "\n",
    "        plt.plot(x, y, label=\"Temperatura\", linewidth=2.5, color='#2980B9')\n",
    "\n",
    "        plt.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Ovulación')\n",
    "        plt.axvline(x=dia_antes_opt, color='green', linestyle='--', linewidth=2, label=f'Día {dia_antes_opt}')\n",
    "        plt.axvline(x=dia_despues_opt, color='orange', linestyle='--', linewidth=2, label=f'Día {dia_despues_opt}')\n",
    "\n",
    "        plt.title(f'Serie {id}')\n",
    "        plt.xlabel('Día relativo a la ovulación')\n",
    "        plt.ylabel('Temperatura (°C)')\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.xlim(RANGE_VISUALIZ_X[0], RANGE_VISUALIZ_X[1])\n",
    "        plt.ylim(RANGE_VISUALIZ_Y[0], RANGE_VISUALIZ_Y[1])  \n",
    "\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5686d46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_series(dia_antes_opt, dia_despues_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd5e1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
