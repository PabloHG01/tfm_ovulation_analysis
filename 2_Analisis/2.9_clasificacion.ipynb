{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e966396",
   "metadata": {},
   "source": [
    "# Pruebas clasificación: tramos máximos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda78a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2914d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../procData/dataset_series_temporales_tramos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc31c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_0</th>\n",
       "      <th>t_1</th>\n",
       "      <th>t_2</th>\n",
       "      <th>t_3</th>\n",
       "      <th>t_4</th>\n",
       "      <th>t_5</th>\n",
       "      <th>t_6</th>\n",
       "      <th>t_7</th>\n",
       "      <th>t_8</th>\n",
       "      <th>t_9</th>\n",
       "      <th>...</th>\n",
       "      <th>t_48</th>\n",
       "      <th>t_49</th>\n",
       "      <th>t_50</th>\n",
       "      <th>t_51</th>\n",
       "      <th>t_52</th>\n",
       "      <th>t_53</th>\n",
       "      <th>t_54</th>\n",
       "      <th>t_55</th>\n",
       "      <th>t_56</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.369506</td>\n",
       "      <td>36.445393</td>\n",
       "      <td>36.476059</td>\n",
       "      <td>36.579726</td>\n",
       "      <td>36.495129</td>\n",
       "      <td>36.510726</td>\n",
       "      <td>36.550393</td>\n",
       "      <td>36.567393</td>\n",
       "      <td>36.530059</td>\n",
       "      <td>36.556726</td>\n",
       "      <td>...</td>\n",
       "      <td>36.567735</td>\n",
       "      <td>36.470594</td>\n",
       "      <td>36.363055</td>\n",
       "      <td>36.478064</td>\n",
       "      <td>36.606093</td>\n",
       "      <td>36.513609</td>\n",
       "      <td>36.552768</td>\n",
       "      <td>36.536643</td>\n",
       "      <td>36.502069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.329549</td>\n",
       "      <td>36.363716</td>\n",
       "      <td>36.363716</td>\n",
       "      <td>36.363716</td>\n",
       "      <td>36.363716</td>\n",
       "      <td>36.363716</td>\n",
       "      <td>36.363716</td>\n",
       "      <td>36.363716</td>\n",
       "      <td>36.363716</td>\n",
       "      <td>36.363716</td>\n",
       "      <td>...</td>\n",
       "      <td>36.910982</td>\n",
       "      <td>36.888416</td>\n",
       "      <td>36.772277</td>\n",
       "      <td>36.748570</td>\n",
       "      <td>36.878558</td>\n",
       "      <td>36.710686</td>\n",
       "      <td>36.820710</td>\n",
       "      <td>36.615203</td>\n",
       "      <td>36.577215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.529684</td>\n",
       "      <td>36.505774</td>\n",
       "      <td>36.517708</td>\n",
       "      <td>36.413560</td>\n",
       "      <td>36.356226</td>\n",
       "      <td>36.264115</td>\n",
       "      <td>36.284450</td>\n",
       "      <td>36.178043</td>\n",
       "      <td>35.995197</td>\n",
       "      <td>35.956195</td>\n",
       "      <td>...</td>\n",
       "      <td>36.481226</td>\n",
       "      <td>36.436893</td>\n",
       "      <td>36.453185</td>\n",
       "      <td>36.433585</td>\n",
       "      <td>36.423226</td>\n",
       "      <td>36.423011</td>\n",
       "      <td>36.426724</td>\n",
       "      <td>36.339037</td>\n",
       "      <td>36.372914</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.369121</td>\n",
       "      <td>36.476743</td>\n",
       "      <td>36.533076</td>\n",
       "      <td>36.489076</td>\n",
       "      <td>36.518516</td>\n",
       "      <td>36.518516</td>\n",
       "      <td>36.518516</td>\n",
       "      <td>36.518516</td>\n",
       "      <td>36.518516</td>\n",
       "      <td>36.518516</td>\n",
       "      <td>...</td>\n",
       "      <td>36.500410</td>\n",
       "      <td>36.427076</td>\n",
       "      <td>36.461410</td>\n",
       "      <td>36.311729</td>\n",
       "      <td>36.321020</td>\n",
       "      <td>36.550743</td>\n",
       "      <td>36.638943</td>\n",
       "      <td>36.692510</td>\n",
       "      <td>36.570243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.540847</td>\n",
       "      <td>36.556513</td>\n",
       "      <td>36.494513</td>\n",
       "      <td>36.484180</td>\n",
       "      <td>36.640513</td>\n",
       "      <td>36.569513</td>\n",
       "      <td>36.503524</td>\n",
       "      <td>36.509206</td>\n",
       "      <td>36.507408</td>\n",
       "      <td>36.526513</td>\n",
       "      <td>...</td>\n",
       "      <td>36.641833</td>\n",
       "      <td>36.569513</td>\n",
       "      <td>36.520180</td>\n",
       "      <td>36.592847</td>\n",
       "      <td>36.574862</td>\n",
       "      <td>36.609180</td>\n",
       "      <td>36.550027</td>\n",
       "      <td>36.580847</td>\n",
       "      <td>36.550180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>36.664017</td>\n",
       "      <td>36.535351</td>\n",
       "      <td>36.351017</td>\n",
       "      <td>36.445684</td>\n",
       "      <td>36.580139</td>\n",
       "      <td>36.718351</td>\n",
       "      <td>36.861684</td>\n",
       "      <td>36.740827</td>\n",
       "      <td>36.660261</td>\n",
       "      <td>36.781684</td>\n",
       "      <td>...</td>\n",
       "      <td>36.754042</td>\n",
       "      <td>36.684772</td>\n",
       "      <td>36.504452</td>\n",
       "      <td>36.671579</td>\n",
       "      <td>36.671358</td>\n",
       "      <td>36.687695</td>\n",
       "      <td>36.868684</td>\n",
       "      <td>36.957767</td>\n",
       "      <td>36.487017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>36.735193</td>\n",
       "      <td>36.755460</td>\n",
       "      <td>36.621460</td>\n",
       "      <td>36.661794</td>\n",
       "      <td>36.654460</td>\n",
       "      <td>36.703794</td>\n",
       "      <td>36.496794</td>\n",
       "      <td>36.514460</td>\n",
       "      <td>36.693794</td>\n",
       "      <td>36.680460</td>\n",
       "      <td>...</td>\n",
       "      <td>36.494127</td>\n",
       "      <td>36.494127</td>\n",
       "      <td>36.494127</td>\n",
       "      <td>36.494127</td>\n",
       "      <td>36.494127</td>\n",
       "      <td>36.494127</td>\n",
       "      <td>36.494127</td>\n",
       "      <td>36.494127</td>\n",
       "      <td>36.494127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>36.546749</td>\n",
       "      <td>36.640105</td>\n",
       "      <td>36.592957</td>\n",
       "      <td>36.384360</td>\n",
       "      <td>36.658105</td>\n",
       "      <td>36.560438</td>\n",
       "      <td>36.639105</td>\n",
       "      <td>36.656105</td>\n",
       "      <td>36.636105</td>\n",
       "      <td>36.613105</td>\n",
       "      <td>...</td>\n",
       "      <td>36.573991</td>\n",
       "      <td>36.574105</td>\n",
       "      <td>36.601105</td>\n",
       "      <td>36.641438</td>\n",
       "      <td>36.665438</td>\n",
       "      <td>36.686105</td>\n",
       "      <td>36.640105</td>\n",
       "      <td>36.596438</td>\n",
       "      <td>36.514833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>36.674175</td>\n",
       "      <td>36.614324</td>\n",
       "      <td>36.681703</td>\n",
       "      <td>36.704525</td>\n",
       "      <td>36.840268</td>\n",
       "      <td>36.770990</td>\n",
       "      <td>36.645036</td>\n",
       "      <td>36.671370</td>\n",
       "      <td>36.689036</td>\n",
       "      <td>36.591703</td>\n",
       "      <td>...</td>\n",
       "      <td>36.857411</td>\n",
       "      <td>36.859319</td>\n",
       "      <td>36.942658</td>\n",
       "      <td>37.070345</td>\n",
       "      <td>36.977359</td>\n",
       "      <td>36.545703</td>\n",
       "      <td>36.545703</td>\n",
       "      <td>36.545703</td>\n",
       "      <td>36.545703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>36.631935</td>\n",
       "      <td>36.631935</td>\n",
       "      <td>36.631935</td>\n",
       "      <td>36.631935</td>\n",
       "      <td>36.661832</td>\n",
       "      <td>36.683535</td>\n",
       "      <td>36.655363</td>\n",
       "      <td>36.682231</td>\n",
       "      <td>36.820206</td>\n",
       "      <td>36.795887</td>\n",
       "      <td>...</td>\n",
       "      <td>36.815456</td>\n",
       "      <td>36.737491</td>\n",
       "      <td>36.575575</td>\n",
       "      <td>36.698135</td>\n",
       "      <td>36.909934</td>\n",
       "      <td>36.500275</td>\n",
       "      <td>36.500275</td>\n",
       "      <td>36.500275</td>\n",
       "      <td>36.500275</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           t_0        t_1        t_2        t_3        t_4        t_5  \\\n",
       "0    36.369506  36.445393  36.476059  36.579726  36.495129  36.510726   \n",
       "1    36.329549  36.363716  36.363716  36.363716  36.363716  36.363716   \n",
       "2    36.529684  36.505774  36.517708  36.413560  36.356226  36.264115   \n",
       "3    36.369121  36.476743  36.533076  36.489076  36.518516  36.518516   \n",
       "4    36.540847  36.556513  36.494513  36.484180  36.640513  36.569513   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "169  36.664017  36.535351  36.351017  36.445684  36.580139  36.718351   \n",
       "170  36.735193  36.755460  36.621460  36.661794  36.654460  36.703794   \n",
       "171  36.546749  36.640105  36.592957  36.384360  36.658105  36.560438   \n",
       "172  36.674175  36.614324  36.681703  36.704525  36.840268  36.770990   \n",
       "173  36.631935  36.631935  36.631935  36.631935  36.661832  36.683535   \n",
       "\n",
       "           t_6        t_7        t_8        t_9  ...       t_48       t_49  \\\n",
       "0    36.550393  36.567393  36.530059  36.556726  ...  36.567735  36.470594   \n",
       "1    36.363716  36.363716  36.363716  36.363716  ...  36.910982  36.888416   \n",
       "2    36.284450  36.178043  35.995197  35.956195  ...  36.481226  36.436893   \n",
       "3    36.518516  36.518516  36.518516  36.518516  ...  36.500410  36.427076   \n",
       "4    36.503524  36.509206  36.507408  36.526513  ...  36.641833  36.569513   \n",
       "..         ...        ...        ...        ...  ...        ...        ...   \n",
       "169  36.861684  36.740827  36.660261  36.781684  ...  36.754042  36.684772   \n",
       "170  36.496794  36.514460  36.693794  36.680460  ...  36.494127  36.494127   \n",
       "171  36.639105  36.656105  36.636105  36.613105  ...  36.573991  36.574105   \n",
       "172  36.645036  36.671370  36.689036  36.591703  ...  36.857411  36.859319   \n",
       "173  36.655363  36.682231  36.820206  36.795887  ...  36.815456  36.737491   \n",
       "\n",
       "          t_50       t_51       t_52       t_53       t_54       t_55  \\\n",
       "0    36.363055  36.478064  36.606093  36.513609  36.552768  36.536643   \n",
       "1    36.772277  36.748570  36.878558  36.710686  36.820710  36.615203   \n",
       "2    36.453185  36.433585  36.423226  36.423011  36.426724  36.339037   \n",
       "3    36.461410  36.311729  36.321020  36.550743  36.638943  36.692510   \n",
       "4    36.520180  36.592847  36.574862  36.609180  36.550027  36.580847   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "169  36.504452  36.671579  36.671358  36.687695  36.868684  36.957767   \n",
       "170  36.494127  36.494127  36.494127  36.494127  36.494127  36.494127   \n",
       "171  36.601105  36.641438  36.665438  36.686105  36.640105  36.596438   \n",
       "172  36.942658  37.070345  36.977359  36.545703  36.545703  36.545703   \n",
       "173  36.575575  36.698135  36.909934  36.500275  36.500275  36.500275   \n",
       "\n",
       "          t_56  label  \n",
       "0    36.502069      1  \n",
       "1    36.577215      1  \n",
       "2    36.372914      1  \n",
       "3    36.570243      1  \n",
       "4    36.550180      1  \n",
       "..         ...    ...  \n",
       "169  36.487017      0  \n",
       "170  36.494127      0  \n",
       "171  36.514833      0  \n",
       "172  36.545703      0  \n",
       "173  36.500275      0  \n",
       "\n",
       "[174 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35fc18bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Datos\n",
    "X = df.drop(\"label\", axis=1).values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# Configuración de validación cruzada\n",
    "skf = KFold(n_splits=58*3, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6fa06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85       116\n",
      "           1       0.81      0.45      0.58        58\n",
      "\n",
      "    accuracy                           0.78       174\n",
      "   macro avg       0.79      0.70      0.72       174\n",
      "weighted avg       0.79      0.78      0.76       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Modelo\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "y_pred = cross_val_predict(clf, X, y, cv=skf)\n",
    "\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a31b2651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85       116\n",
      "           1       0.79      0.47      0.59        58\n",
      "\n",
      "    accuracy                           0.78       174\n",
      "   macro avg       0.79      0.70      0.72       174\n",
      "weighted avg       0.78      0.78      0.76       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=skf)\n",
    "\n",
    "print(classification_report(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51488816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.94      0.83       116\n",
      "           1       0.75      0.36      0.49        58\n",
      "\n",
      "    accuracy                           0.75       174\n",
      "   macro avg       0.75      0.65      0.66       174\n",
      "weighted avg       0.75      0.75      0.72       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=skf)\n",
    "\n",
    "print(classification_report(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cd77ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73       116\n",
      "           1       0.48      0.50      0.49        58\n",
      "\n",
      "    accuracy                           0.65       174\n",
      "   macro avg       0.61      0.61      0.61       174\n",
      "weighted avg       0.65      0.65      0.65       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='poly', probability=True, random_state=42)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=skf)\n",
    "\n",
    "print(classification_report(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cb59e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80       116\n",
      "           1       0.00      0.00      0.00        58\n",
      "\n",
      "    accuracy                           0.67       174\n",
      "   macro avg       0.33      0.50      0.40       174\n",
      "weighted avg       0.44      0.67      0.53       174\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='sigmoid', probability=True, random_state=42)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=skf)\n",
    "\n",
    "print(classification_report(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5c71bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.91      0.82       116\n",
      "           1       0.67      0.34      0.45        58\n",
      "\n",
      "    accuracy                           0.72       174\n",
      "   macro avg       0.70      0.63      0.63       174\n",
      "weighted avg       0.71      0.72      0.70       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=skf)\n",
    "\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85b3f0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.68      0.74       116\n",
      "           1       0.52      0.69      0.59        58\n",
      "\n",
      "    accuracy                           0.68       174\n",
      "   macro avg       0.67      0.69      0.67       174\n",
      "weighted avg       0.72      0.68      0.69       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "y_pred = cross_val_predict(clf, X, y, cv=skf)\n",
    "\n",
    "print(classification_report(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe1c6bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       116\n",
      "           1       0.72      0.53      0.61        58\n",
      "\n",
      "    accuracy                           0.78       174\n",
      "   macro avg       0.76      0.72      0.73       174\n",
      "weighted avg       0.77      0.78      0.77       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=42)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=skf)\n",
    "\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b5da6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       116\n",
      "           1       0.64      0.50      0.56        58\n",
      "\n",
      "    accuracy                           0.74       174\n",
      "   macro avg       0.71      0.68      0.69       174\n",
      "weighted avg       0.73      0.74      0.73       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier()\n",
    "\n",
    "y_pred = cross_val_predict(clf, X, y, cv=skf)\n",
    "\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed073853",
   "metadata": {},
   "source": [
    "## Mejores modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97f78d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf27bb4d",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aab9a8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 174 folds for each of 324 candidates, totalling 56376 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Mejor puntuación F1 (macro): 0.7931034482758621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:18:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:19:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.85       116\n",
      "           1       0.76      0.48      0.59        58\n",
      "\n",
      "    accuracy                           0.78       174\n",
      "   macro avg       0.77      0.70      0.72       174\n",
      "weighted avg       0.77      0.78      0.76       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 4, 6],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1],\n",
    "    'gamma': [0, 0.1, 0.3]\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_macro',  # puedes usar 'accuracy', 'recall_macro', etc.\n",
    "    cv=skf,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Mejor modelo y resultados\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación F1 (macro):\", grid_search.best_score_)\n",
    "\n",
    "# Predicción con el mejor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = cross_val_predict(best_model, X, y, cv=skf)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4e78ab",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee42276b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 174 folds for each of 10 candidates, totalling 1740 fits\n",
      "Mejores parámetros: {'var_smoothing': np.float64(1e-11)}\n",
      "Mejor puntuación F1 (macro): 0.6839080459770115\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.68      0.74       116\n",
      "           1       0.52      0.69      0.59        58\n",
      "\n",
      "    accuracy                           0.68       174\n",
      "   macro avg       0.67      0.69      0.67       174\n",
      "weighted avg       0.72      0.68      0.69       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Rango de var_smoothing (usualmente entre 1e-9 y 1e-6 es útil)\n",
    "param_grid = {\n",
    "    'var_smoothing': np.logspace(-11, -6, 10)\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=gnb,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=skf,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entrenar\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Resultados\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación F1 (macro):\", grid_search.best_score_)\n",
    "\n",
    "# Predicciones con el mejor modelo\n",
    "best_gnb = grid_search.best_estimator_\n",
    "y_pred = cross_val_predict(best_gnb, X, y, cv=skf)\n",
    "print(classification_report(y, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
